{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071278e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.types import Send, interrupt, Command\n",
    "from typing import TypedDict\n",
    "import subprocess\n",
    "from openai import OpenAI\n",
    "import textwrap\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import Annotated\n",
    "import operator\n",
    "import base64\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    \n",
    "    video_file: str # ë¹„ë””ì˜¤íŒŒì¼ ê²½ë¡œ\n",
    "    audio_file: str # ì˜¤ë””ì˜¤íŒŒì¼ ê²½ë¡œ\n",
    "    transcription: str # ì¶”ì¶œëœ ìŒì„±\n",
    "    summaries: Annotated[list[str], operator.add] # ìš”ì•½ ë¬¸ì¥ ëª©ë¡\n",
    "    final_summary: str\n",
    "\n",
    "    thumbnail_prompts: Annotated[list[str], operator.add]\n",
    "    thumbnail_sketches: Annotated[list[str], operator.add]\n",
    "\n",
    "    user_feedback: str\n",
    "    chosen_prompt: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6325d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(state: State):\n",
    "    # Using ffmpeg to extract audio from video\n",
    "    output_file = state[\"video_file\"].replace(\"mp4\", \"mp3\")\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        state[\"video_file\"],\n",
    "        \"-filter:a\",\n",
    "        \"atempo=1.7\",\n",
    "        \"-y\",\n",
    "        output_file\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "    return {\n",
    "        \"audio_file\": output_file\n",
    "    }\n",
    "\n",
    "WHISPER_PROMPT = (\n",
    "    \"ì´ ì˜¤ë””ì˜¤ëŠ” â€˜ëˆíƒ€í´ë¡œìŠ¤â€™ ìœ íŠœë¸Œ ì±„ë„ì˜ â€˜ìƒí‘œë“±ë¡ ë°©ë²•â€™ ì•ˆë‚´ì…ë‹ˆë‹¤. í•œêµ­ íŠ¹í—ˆì²­(KIPO)ê³¼ KIPRISë¥¼ ì „ì œë¡œ ìƒí‘œê²€ìƒ‰, ì¶œì›, ì‹¬ì‚¬, ë³´ì •, \"\n",
    "    \"ì˜ê²¬ì œì¶œí†µì§€, ê±°ì ˆì´ìœ , ë“±ë¡ê²°ì •, ê°±ì‹ ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë‹ˆìŠ¤ êµ­ì œë¶„ë¥˜(1~45ë¥˜), ìœ ì‚¬êµ°ì½”ë“œ, ì§€ì •ìƒí’ˆ, \"\n",
    "    \"ì¶œì›ìˆ˜ìˆ˜ë£Œ/ë“±ë¡ë£Œ ë“± ìˆ«ìì™€ ë¶„ë¥˜í‘œê¸°ëŠ” ì •í™•íˆ ìˆ«ìë¡œ í‘œê¸°í•˜ì„¸ìš”(ì˜ˆ: 35ë¥˜, 45ë¥˜). \"\n",
    "    \"ë¸Œëœë“œÂ·ì…€ëŸ¬(ì¿ íŒ¡, ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´, ì•„ë§ˆì¡´)ëŠ” í•œê¸€ ê·¸ëŒ€ë¡œ í‘œê¸°í•˜ê³ , ê³ ìœ ëª…ì‚¬ëŠ” ì˜¤íƒˆì ì—†ì´ ì ìŠµë‹ˆë‹¤. \"\n",
    "    \"í•µì‹¬ ìš©ì–´: ìƒí‘œë“±ë¡, ìƒí‘œì¶œì›, ìƒí‘œê²€ìƒ‰, ì§€ì‹ì¬ì‚°ê¶Œ, ë¸Œëœë“œë³´í˜¸, ì§€ì •ìƒí’ˆ, ìœ ì‚¬êµ°ì½”ë“œ, ì¶œì›ë²ˆí˜¸, ê±°ì ˆì´ìœ , \"\n",
    "    \"ë“±ë¡ê²°ì •, ê°±ì‹ , KIPRIS, íŠ¹í—ˆì²­. \"\n",
    "    \"English terms: KIPO, KIPRIS, Nice Classification, Classes 1â€“45, trademark search, office action, refusal, registration decision, renewal.\"\n",
    ")\n",
    "def transcribe_audio(state: State):\n",
    "    # use audio file\n",
    "    client = OpenAI()\n",
    "    with open(state[\"audio_file\"], \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"text\",\n",
    "            file=audio_file,\n",
    "            language=\"ko\",\n",
    "            prompt=WHISPER_PROMPT\n",
    "        )\n",
    "        return {\n",
    "            \"transcription\": transcription\n",
    "        }\n",
    "\n",
    "def dispatch_summarizers(state: State):\n",
    "    transcription = state[\"transcription\"]\n",
    "    chunks = []\n",
    "    for idx, chunk in enumerate(textwrap.wrap(transcription, 500)):\n",
    "        chunks.append({\n",
    "            \"id\": idx+1,\n",
    "            \"chunk\": chunk\n",
    "        })\n",
    "    return [Send(\"summarize_chunk\", chunk) for chunk in chunks]\n",
    "\n",
    "def summarize_chunk(chunk):\n",
    "    chunk_id = chunk[\"id\"]\n",
    "    chunk_text = chunk[\"chunk\"]\n",
    "\n",
    "    response = llm.invoke(\n",
    "        f\"\"\"ì´ ë¬¸ì¥ì„ ìš”ì•½í•´ì¤˜.\n",
    "            Text : {chunk_text}\"\"\"        \n",
    "    )\n",
    "    summary = f\"[Chunk {chunk_id}] {response.content}\";\n",
    "    return {\n",
    "        \"summaries\" : [summary]\n",
    "    }\n",
    "\n",
    "def finalize_summary(state: State):\n",
    "    all_summaries = \"\\n\".join(state[\"summaries\"])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        you are given multiple summarise of different chunks from a video transcription.\n",
    "        \n",
    "        Please create a comprehensive final summary the combines all the key points.\n",
    "\n",
    "        Individual summaries :        \n",
    "\n",
    "        {all_summaries}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\n",
    "        \"final_summary\": response.content\n",
    "    }\n",
    "\n",
    "def dispatch_artists(state: State):\n",
    "    # return [Send(\"generate_thumbnail\", state) for i in [1, 2, 3]]\n",
    "    return [\n",
    "            Send(\n",
    "                \"generate_thumbnail\", \n",
    "                {\n",
    "                    \"id\":i , \n",
    "                    \"summary\": state[\"final_summary\"],\n",
    "                }\n",
    "            ) \n",
    "            for i in [1, 2, 3, 4, 5]\n",
    "        ]\n",
    "\n",
    "def generate_thumbnail(args):\n",
    "    concept_id = args[\"id\"]\n",
    "    summary = args[\"summary\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are an expert Korean thumbnail designer AI generating an image with the GPT-image-1 model.\n",
    "\n",
    "        ğŸ¯ GOAL:\n",
    "        Create a YouTube thumbnail that attracts Korean viewers based on the following video summary.\n",
    "        This thumbnail must look professional, eye-catching, and optimized for Korean YouTube audiences.\n",
    "\n",
    "        âš ï¸ LANGUAGE RULES (IMPORTANT):\n",
    "        - **All visible text in the thumbnail must be written in Korean (Hangul only)**.\n",
    "        - **Never use English letters or Romanized Korean.**\n",
    "        - **Do not translate Korean text into English.**\n",
    "        - The Korean text must be perfectly rendered â€” no broken or corrupted Hangul characters.\n",
    "        - Use proper spacing, alignment, and typographic consistency for Hangul.\n",
    "        - Prioritize accurate Hangul rendering over stylistic effects.\n",
    "        - If the model struggles to draw Hangul text, focus on producing realistic, clean Korean lettering.\n",
    "        - Use strong, readable Korean title fonts such as **Noto Sans KR**, **Pretendard Bold**, or **Nanum Gothic ExtraBold**.\n",
    "\n",
    "        ğŸ§© INSTRUCTIONS:\n",
    "        Generate a detailed visual prompt that includes:\n",
    "        1. **Main visual elements** â€” Describe characters, objects, or icons that represent the topic.\n",
    "        2. **Color scheme** â€” Suggest harmonious, bright color palettes suitable for Korean audiences.\n",
    "        3. **Text overlay (Korean phrases only)** â€” Propose 2â€“3 short, catchy Korean phrases to display on the thumbnail.\n",
    "        4. **Overall composition** â€” Describe the layout, focal points, and balance between text and visuals.\n",
    "\n",
    "        ğŸ–‹ STYLE GUIDELINES:\n",
    "        - The thumbnail should look modern, clean, and professional.\n",
    "        - Avoid clutter; maintain focus on the main message.\n",
    "        - Korean text should stand out clearly against the background.\n",
    "        - Use contrast (dark text on bright background or vice versa).\n",
    "        - Recommended aspect ratio: 16:9 (YouTube thumbnail standard).\n",
    "\n",
    "        ğŸ’¬ EXAMPLE:\n",
    "        If the summary is about \"ìƒí‘œë“±ë¡ ë°©ë²•\",\n",
    "        - Text overlay suggestions: \n",
    "            - \"5ë¶„ ë§Œì— ëë‚´ëŠ” ìƒí‘œë“±ë¡\"\n",
    "            - \"ì´ˆë³´ë„ ê°€ëŠ¥í•œ ë¸Œëœë“œ ë“±ë¡ ê¿€íŒ\"\n",
    "        - Visual: smiling Korean entrepreneur holding a trademark certificate, with the KIPO (íŠ¹í—ˆì²­) building faintly visible.\n",
    "        - Background: light blue and white gradient conveying trust and clarity.\n",
    "\n",
    "        ğŸ“„ VIDEO SUMMARY:\n",
    "        {summary}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    thumbnail_prompt = response.content\n",
    "\n",
    "    client = OpenAI()\n",
    "    image = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=thumbnail_prompt,\n",
    "        quality=\"low\",\n",
    "        moderation=\"low\",\n",
    "        size=\"auto\",\n",
    "        \n",
    "    )\n",
    "\n",
    "    image_bytes = base64.b64decode(image.data[0].b64_json)\n",
    "\n",
    "    filename = f\"thumbnail_{concept_id}.jpg\"\n",
    "\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(image_bytes)\n",
    "\n",
    "    return {\n",
    "        \"thumbnail_prompts\":[thumbnail_prompt],\n",
    "        \"thumbnail_sketches\":[filename]\n",
    "    }\n",
    "    \n",
    "\n",
    "def human_feedback(state: State):\n",
    "    answer = interrupt({\n",
    "        \"chosen_thumbnail\": \"ì–´ë–¤ ì¸ë„¤ì¼ì´ ê°€ì¥ ë§ˆìŒì— ë“œë‚˜ìš”?\",\n",
    "        \"feedback\": \"ì¸ë„¤ì¼ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.\"\n",
    "    })\n",
    "\n",
    "    user_feedback = answer[\"user_feedback\"]\n",
    "    chosen_prompt = answer[\"chosen_prompt\"]\n",
    "    \n",
    "    return {\n",
    "        \"user_feedback\" : user_feedback,\n",
    "        \"chosen_prompt\" : state[\"thumbnail_prompts\"][chosen_prompt-1]\n",
    "    }\n",
    "\n",
    "def generate_hd_thumbnail(state: State):\n",
    "    chosen_prompt = state[\"chosen_prompt\"]\n",
    "    user_feedback = state[\"user_feedback\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are a professional YouTube thumbnail designer. Take this original thumbnail prompt and create an enhanced version that incorporates the user's specific feedback.\n",
    "\n",
    "        ORIGINAL PROMPT:\n",
    "        {chosen_prompt}\n",
    "\n",
    "        USER FEEDBACK TO INCORPORATE:\n",
    "        {user_feedback}\n",
    "\n",
    "        Create an enhanced prompt that:\n",
    "            1. Maintains the core concept from the original prompt\n",
    "            2. Specifically addresses and implements the user's feedback requests\n",
    "            3. Adds professional YouTube thumbnail specifications:\n",
    "                - High contrast and bold visual elements\n",
    "                - Clear focal points that draw the eye\n",
    "                - Professional lighting and composition\n",
    "                - Optimal text placement and readability with generous padding from edges\n",
    "                - Colors that pop and grab attention\n",
    "                - Elements that work well at small thumbnail sizes\n",
    "                - IMPORTANT: Always ensure adequate white space/padding between any text and the image borders\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    final_thumbnail_prompt = response.content\n",
    "\n",
    "    client = OpenAI()\n",
    "    image = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=final_thumbnail_prompt,\n",
    "        quality=\"high\",\n",
    "        moderation=\"low\",\n",
    "        size=\"auto\",\n",
    "        \n",
    "    )\n",
    "\n",
    "    image_bytes = base64.b64decode(image.data[0].b64_json)\n",
    "\n",
    "    with open(\"thumbnail_final.jpg\", \"wb\") as file:\n",
    "        file.write(image_bytes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b775353",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"extract_audio\", extract_audio)\n",
    "graph_builder.add_node(\"transcribe_audio\", transcribe_audio)\n",
    "graph_builder.add_node(\"summarize_chunk\", summarize_chunk)\n",
    "graph_builder.add_node(\"finalize_summary\", finalize_summary)\n",
    "graph_builder.add_node(\"generate_thumbnail\", generate_thumbnail)\n",
    "graph_builder.add_node(\"human_feedback\", human_feedback)\n",
    "graph_builder.add_node(\"generate_hd_thumbnail\", generate_hd_thumbnail)\n",
    "\n",
    "\n",
    "graph_builder.add_edge(START, \"extract_audio\")\n",
    "graph_builder.add_edge(\"extract_audio\", \"transcribe_audio\")\n",
    "graph_builder.add_conditional_edges(\"transcribe_audio\", dispatch_summarizers, [\"summarize_chunk\"])\n",
    "graph_builder.add_edge(\"summarize_chunk\", \"finalize_summary\")\n",
    "graph_builder.add_conditional_edges(\"finalize_summary\", dispatch_artists, [\"generate_thumbnail\"])\n",
    "graph_builder.add_edge(\"generate_thumbnail\", \"human_feedback\")\n",
    "graph_builder.add_edge(\"human_feedback\", \"generate_hd_thumbnail\")\n",
    "graph_builder.add_edge(\"human_feedback\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": \"1\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"video_file\": \"./data/input_video.mp4\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "snapshot.interrupts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "    \"chosen_prompt\":3,\n",
    "    \"user_feedback\":\"ë‚¨ìì™€ ì—¬ìê°€ ì›ƒê³ ìˆê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ì¢Œì¸¡ ìƒë‹¨ì˜ ì‹œê³„ëŠ” ì‹¤ì œ ì‹œê³„ì²˜ëŸ¼ ë³´ì´ê²Œ ë¦¬ì–¼í•œ 3Dë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ìš°ì¸¡ R ë¡œê³ ëŠ” ì‚­ì œí•´ì£¼ì„¸ìš”.\"\n",
    "}\n",
    "\n",
    "graph.invoke(Command(resume=response), config=config)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
