{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluator–Optimizer Workflow (상세페이지 자동 생성용)\n",
    "---------------------------------------------------\n",
    "- LangGraph StateGraph + 명시적 State 타입(TypedDict)\n",
    "- Generator / Evaluator (Feedback 흡수) 2-노드 구조\n",
    "- 비용 최적화: gpt-4o-mini\n",
    "- 프롬프트 외부 .md 파일 분리\n",
    "- 조건부 전이 + (필요 시) Command/Send로 직접 재호출\n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Optional, Dict, Any\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command, Send\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import json, os\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 모델 설정 (비용 효율)\n",
    "# =========================================================\n",
    "GEN_MODEL = \"gpt-4o-mini\"\n",
    "EVAL_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "llm_generator = ChatOpenAI(model=GEN_MODEL, temperature=0.7)\n",
    "llm_evaluator = ChatOpenAI(model=EVAL_MODEL, temperature=0.3)\n",
    "\n",
    "# =========================================================\n",
    "# 헬퍼 - 프롬프트 로더\n",
    "# =========================================================\n",
    "GEN_PROMPT_PATH = \"./prompts/generator_prompt.md\"\n",
    "EVAL_PROMPT_PATH = \"./prompts/evaluator_prompt.md\"\n",
    "\n",
    "def load_prompt(path: str) -> str:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Prompt file not found: {path}\")\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().strip()\n",
    "        \n",
    "\n",
    "# =========================================================\n",
    "# 1) State 정의\n",
    "# =========================================================\n",
    "class State(TypedDict):\n",
    "    meta: Dict[str, Any]                  # 제품 메타정보 (입력)\n",
    "    draft: Optional[str]                  # Generator 결과 (초안)\n",
    "    evaluation: Optional[Dict[str, Any]]  # Evaluator JSON 평가 결과\n",
    "    feedback: Optional[str]               # 수정 지시사항(누적/최신)\n",
    "    iteration: int                        # 루프 카운트\n",
    "\n",
    "# =========================================================\n",
    "# 2) 평가 결과 스키마\n",
    "# =========================================================\n",
    "class EvalResult(BaseModel):\n",
    "    score: float = Field(..., ge=0, le=100)\n",
    "    pass_: bool = Field(..., alias=\"pass\")\n",
    "    revise_instructions: list[str] = []\n",
    "    violations: list[dict] = []\n",
    "    \n",
    "# =========================================================\n",
    "# 1) 노드: Generator\n",
    "# =========================================================\n",
    "def node_generate(state: State) -> State:\n",
    "    meta = state[\"meta\"]\n",
    "    feedback = state.get(\"feedback\") or \"초안 1회차: 기본 작성\"\n",
    "    base_prompt = load_prompt(GEN_PROMPT_PATH)\n",
    "\n",
    "    prompt = base_prompt.format(\n",
    "        product_name=meta[\"product_name\"],\n",
    "        target_audience=meta[\"target_audience\"],\n",
    "        seo_keywords=\", \".join(meta[\"seo_keywords\"]),\n",
    "        certs_or_tests=meta.get(\"certs_or_tests\", \"없음\"),\n",
    "        banned_terms=\", \".join(meta.get(\"banned_terms\", [])),\n",
    "        feedback=feedback,\n",
    "    )\n",
    "\n",
    "    resp = llm_generator.invoke(prompt)\n",
    "    return {**state, \"draft\": resp.content, \"iteration\": state[\"iteration\"] + 1}\n",
    "\n",
    "# =========================================================\n",
    "# 2) 노드: Evaluator (피드백 생성까지 수행)\n",
    "#    - 조건: 통과/최대루프 → 상태만 반환 (조건부 전이로 END)\n",
    "#    - 조건: 미통과 → Command/Send로 Generator 재호출 (Feedback 별도 노드 불필요)\n",
    "# =========================================================\n",
    "def node_evaluate(state: State):\n",
    "    draft = state[\"draft\"]\n",
    "    meta = state[\"meta\"]\n",
    "    eval_prompt_base = load_prompt(EVAL_PROMPT_PATH)\n",
    "\n",
    "    eval_prompt = eval_prompt_base.format(\n",
    "        product_name=meta[\"product_name\"],\n",
    "        draft=draft,\n",
    "    )\n",
    "\n",
    "    resp = llm_evaluator.invoke(eval_prompt)\n",
    "\n",
    "    try:\n",
    "        parsed = EvalResult.parse_raw(resp.content)\n",
    "        evaluation = parsed.dict(by_alias=True)\n",
    "    except Exception:\n",
    "        evaluation = {\n",
    "            \"score\": 0,\n",
    "            \"pass\": False,\n",
    "            \"revise_instructions\": [\"JSON 형식 오류로 인한 재시도 필요\"],\n",
    "            \"violations\": [],\n",
    "        }\n",
    "\n",
    "    # Evaluator가 피드백 생성까지 수행\n",
    "    feedback_lines = evaluation.get(\"revise_instructions\", [])\n",
    "    feedback_text = \"\\n\".join(feedback_lines) if feedback_lines else None\n",
    "\n",
    "    updated: State = {\n",
    "        **state,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"feedback\": feedback_text,\n",
    "    }\n",
    "\n",
    "    # 통과 또는 최대 루프 → 상태만 반환(그래프 조건부 전이로 END)\n",
    "    if (evaluation.get(\"pass\") and evaluation.get(\"score\", 0) >= 90) or (state[\"iteration\"] >= 3):\n",
    "        return updated\n",
    "\n",
    "    # 미통과 → Command/Send를 사용해 즉시 Generator 재호출 (Feedback 노드 불필요)\n",
    "    return Command(\n",
    "        sends=[\n",
    "            Send(\"Generator\", updated)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# =========================================================\n",
    "# 2) 상태 전이 조건 (Evaluator 이후 전이만 정의)\n",
    "#    - node_evaluate에서 Command/Send로 재호출한 경우 조건 전이는 무시됨\n",
    "#    - 상태만 반환된 경우에만 조건 전이가 적용\n",
    "# =========================================================\n",
    "def route_after_eval(state: State) -> str:\n",
    "    eval_res = state.get(\"evaluation\") or {}\n",
    "    if (eval_res.get(\"pass\") and eval_res.get(\"score\", 0) >= 90) or (state.get(\"iteration\", 0) >= 3):\n",
    "        return \"Accepted\"\n",
    "    return \"Rejected+Feedback\"  # 일반적으로 여기 도달하지 않음(미통과 시 evaluator가 Command/Send 사용)\n",
    "    \n",
    "# =========================================================\n",
    "# 그래프 빌드\n",
    "# =========================================================\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"Generator\", node_generate)\n",
    "graph_builder.add_node(\"Evaluator\", node_evaluate)\n",
    "\n",
    "graph_builder.add_edge(START, \"Generator\")\n",
    "graph_builder.add_edge(\"Generator\", \"Evaluator\")\n",
    "graph_builder.add_edge(\"Evaluator\", END)\n",
    "\n",
    "# Evaluator가 상태만 반환(accept/maxed)한 경우에만 END로 전이\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"Evaluator\",\n",
    "    route_after_eval,\n",
    "    {\n",
    "        \"Accepted\": END,\n",
    "        \"Rejected+Feedback\": \"Generator\",  # 안전망(보통 미사용) — evaluator가 Command/Send 실패 시 사용\n",
    "    },\n",
    ")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "# graph\n",
    "\n",
    "meta_info = {\n",
    "    \"product_name\": \"AEMICA 스테인리스 수세미 세트\",\n",
    "    \"target_audience\": \"주부 및 자취생\",\n",
    "    \"seo_keywords\": [\"스테인리스 수세미\", \"주방 청소\", \"위생 세척\"],\n",
    "    \"certs_or_tests\": \"KC 인증 완료\",\n",
    "    \"banned_terms\": [\"완벽\", \"기적\", \"100%\"],\n",
    "}\n",
    "\n",
    "initial_state: State = {\n",
    "    \"meta\": meta_info,\n",
    "    \"draft\": None,\n",
    "    \"evaluation\": None,\n",
    "    \"feedback\": None,\n",
    "    \"iteration\": 0,\n",
    "}\n",
    "\n",
    "result  = graph.invoke(initial_state)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
